# Nov 25 Mon

Blue Monday

Rainy, $9$℃

Moist $76\%$

South Wind, $29km/h$

AQI (China Standard): 37

## SE-342::CV

###Review

所谓 Image Segmentation。

* Harris & SIFT Technique

* Based on the pyramids differentiation

* Lowe's pyramid scheme.

### Fore, Back

前景和背景。

###Q&A

#### Q1: SIFT 方法的基本步驟

**尺度不變特徵轉換**(**Scale-invariant feature transform** 或 **SIFT**)是一種[機器視覺](https://zh.wikipedia.org/wiki/机器视觉)的演算法用來偵測與描述影像中的局部性特徵，它在空間尺度中尋找極值點，並提取出其位置、尺度、旋轉不變數，此演算法由 [David Lowe](https://zh.wikipedia.org/w/index.php?title=David_Lowe_(computer_scientist)&action=edit&redlink=1) 在1999年所發表，2004年完善總結。 [[1\]](https://zh.wikipedia.org/wiki/#cite_note-lowe99-1) 後續的論文中也有許多基於 SIFT 改進的論文，例如 [SURF](https://zh.wikipedia.org/wiki/加速稳健特征) 將 SIFT 的許多過程近似，達到加速的效果；PCA-SIFT利用[主成分分析](https://zh.wikipedia.org/wiki/主成分分析)降低描述子的維度，減少記憶體的使用並加快配對速度。

## 特徵[[編輯](https://zh.wikipedia.org/w/index.php?title=尺度不變特徵轉換&action=edit&section=1)]

局部影像特徵的描述與偵測可以幫助辨識物體，SIFT 特徵是基於物體上的一些局部外觀的興趣點而與影像的大小和旋轉無關。 對於光線、雜訊、些微視角改變的容忍度也相當高。基於這些特性，它們是高度顯著而且相對容易擷取，在母數龐大的特徵資料庫中，很容易辨識物體而且鮮有誤認。

使用 SIFT 特徵描述對於部分物體遮蔽的偵測率也相當高，甚至只需要3個以上的 SIFT 物體特徵就足以計算出位置與方位。

在現今的電腦硬體速度下和小型的特徵資料庫條件下，辨識速度可接近即時運算。

SIFT 特徵的信息量大，適合在大量資料庫中快速準確匹配。

## 演算法[[編輯](https://zh.wikipedia.org/w/index.php?title=尺度不變特徵轉換&action=edit&section=2)]

### 尺度空間的極值偵測[[編輯](https://zh.wikipedia.org/w/index.php?title=尺度不變特徵轉換&action=edit&section=3)]

在這個階段，主要是偵測興趣點，也就是SIFT架構中的關鍵點。 影像在不同的尺度下用高斯濾波器(Gaussian filters)進行卷積(convolved)，然後利用連續高斯模糊化影像差異來找出關鍵點。關鍵點是根據不同尺度下的[高斯差](https://zh.wikipedia.org/wiki/高斯差)(Difference of Gaussians,DoG)的最大最小值。 也就是說，DoG影像的D(x,y,σ)![D\left(x,y,\sigma \right)](https://wikimedia.org/api/rest_v1/media/math/render/svg/32ebe4a50fbf3c7d09813ea35a1d049071b654cb) 是由:







由上式可知DoG影像是原始影像與不同尺度倍率kiσ![k_i\sigma](https://wikimedia.org/api/rest_v1/media/math/render/svg/d01edf96d4b6b75667ec0d0bac27448c99017418)、kjσ![k_j\sigma](https://wikimedia.org/api/rest_v1/media/math/render/svg/76a90d77762ecc743fd867acb7bfb403e651c515)的高斯模糊後之差值。 SIFT演算法為了求得在不同尺度倍率之下DoG影像的極大值，先將原始影像與不同尺度倍率的高斯模糊進行卷積，這些經高斯模糊處理後的影像依其尺度倍率以2倍為一單位分組，並且kiσ![k_i\sigma](https://wikimedia.org/api/rest_v1/media/math/render/svg/d01edf96d4b6b75667ec0d0bac27448c99017418)通常為一個選定後的定值，因此在每一組內經高斯模糊處理後的影像數量相同，此時將同一組相鄰的經高斯模糊處理後的影像兩兩相減可得其DoG影像。

一旦得到DoG影像後，可找出DoG影像中的極大、極小值作為關鍵點。為了決定關鍵點，DoG影像中的每個像素會跟以自己為中心周圍的八個像素，以及在同一組DoG影像中相鄰尺度倍率相同位置的九個像素作，一共二十六個點作比較，若此像素為這二十六個像素中的最大、最小值，則此稱此像素為關鍵點。

SIFT演算法中關鍵點的偵測是一種斑點檢測(Blob detection)的一種變形，也就是使用[拉普拉斯運算元](https://zh.wikipedia.org/wiki/拉普拉斯算子)來求出各個倍率及空間中的最大值。高斯差可近似為拉普拉斯運算元運算後的結果，因建立[高斯金字塔](https://zh.wikipedia.org/wiki/高斯金字塔)的過程是一種尺寸正規化拉普拉斯運算的近似。

### 關鍵點定位[[編輯](https://zh.wikipedia.org/w/index.php?title=尺度不變特徵轉換&action=edit&section=4)]

在不同尺寸空間下可能找出過多的關鍵點，有些關鍵點可能相對不易辨識或易受雜訊干擾。SIFT演算法的下一步將會藉由關鍵點附近像素的資訊、關鍵點的尺寸、關鍵點的[主曲率](https://zh.wikipedia.org/wiki/主曲率)來定位各個關鍵點，藉此消除位於邊上或是易受雜訊干擾的關鍵點

#### 鄰近資料插補[[編輯](https://zh.wikipedia.org/w/index.php?title=尺度不變特徵轉換&action=edit&section=5)]

對於各個可能的關鍵點，插補鄰近資料可決定其位置。最一開始的方法為紀錄各個關鍵點在圖片中的位置與尺度。

而新開發出來的方法指出，計算極值得差補位置更能夠提供配對的準確度及可靠性，此方法使用DoG影像D(x,y,σ)![D\left(x,y,\sigma \right)](https://wikimedia.org/api/rest_v1/media/math/render/svg/32ebe4a50fbf3c7d09813ea35a1d049071b654cb)的二次[泰勒級數](https://zh.wikipedia.org/wiki/泰勒级数)，並以關鍵點作為原點，其展開式可寫成:



其中D與其偏微分的值由關鍵點的位置決定，變數x=(x,y,σ)![\textbf{x} = \left( x, y, \sigma \right)](https://wikimedia.org/api/rest_v1/media/math/render/svg/0bd62f77681647d41d51ccb4eceb598577c19c90)則是到此關鍵點的偏移量。

將上式對x![{\textbf  {x}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/85631435f001c884eca834164392982c621f40e2) 微分後設為零，便可求出極值x^![\hat{\textbf{x}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a51ff2ef64578ad2d691347cba94d67b57c2e9ab)的位置。若x^![\hat{\textbf{x}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a51ff2ef64578ad2d691347cba94d67b57c2e9ab)的任一項參數大於0.5，代表此時有另一關鍵點更接近極值，將捨棄此關鍵點並對新的點作插補。反之若所有參數皆小於0.5，此時將偏移量加回關鍵點中找出極值的位置。

#### 捨棄不明顯關鍵點[[編輯](https://zh.wikipedia.org/w/index.php?title=尺度不變特徵轉換&action=edit&section=6)]

此步驟將計算上述二次泰勒級數D(x)![D(\textbf{x})](https://wikimedia.org/api/rest_v1/media/math/render/svg/999fbffd563d66720a18ff91c66e7702d54e98b7)在x^![\hat{\textbf{x}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/a51ff2ef64578ad2d691347cba94d67b57c2e9ab)的值。若此值小於0.03，則捨棄此關鍵點。反之保留此關鍵點，並記錄其位置為y+x^![\textbf{y} + \hat{\textbf{x}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/c8478657a4454df2961bcc2c2ae5211656be2eb0)，其中y![{\textbf  {y}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/9217602eb948f6bfca224665a8b6aac54e15725b)是一開始關鍵點的位置。

#### 消除邊緣響應[[編輯](https://zh.wikipedia.org/w/index.php?title=尺度不變特徵轉換&action=edit&section=7)]

DoG函數對於偵測邊緣上的點相當敏感，即使其找出位於邊緣的關鍵點易受雜訊干擾也會被偵測為關鍵點。 因此為了增加關鍵點的可靠性，需要消除有高度邊緣響應但其位置不佳不符合需求的關鍵點。

為了找出邊緣上的點，可分別計算關鍵點的[主曲率](https://zh.wikipedia.org/wiki/主曲率)，對於在邊上的關鍵點而言，因為穿過邊緣方向的主曲率會遠大於沿著邊緣方向上的主曲率，因此其主曲率比值遠大於位於角落的比值。

為了算出關鍵點的主曲率，可解其二次[海森矩陣](https://zh.wikipedia.org/wiki/海森矩阵)矩陣的特徵值:



其特徵值的比例與特徵點主曲率的比例相同，因此假設解出的特徵值為α![\alpha ](https://wikimedia.org/api/rest_v1/media/math/render/svg/b79333175c8b3f0840bfb4ec41b8072c83ea88d3)、β![\beta ](https://wikimedia.org/api/rest_v1/media/math/render/svg/7ed48a5e36207156fb792fa79d29925d2f7901e8)，其中α>β![\alpha > \beta](https://wikimedia.org/api/rest_v1/media/math/render/svg/878aa4ba937a08258b46361229c9c35d970672ff)。在上述矩陣中:





因此



其中r=α/β![r = \alpha/\beta](https://wikimedia.org/api/rest_v1/media/math/render/svg/a9917f45384a7dbe702bd5e3fe0302374867780b)。由此可知當R越大，α![\alpha ](https://wikimedia.org/api/rest_v1/media/math/render/svg/b79333175c8b3f0840bfb4ec41b8072c83ea88d3)、β![\beta ](https://wikimedia.org/api/rest_v1/media/math/render/svg/7ed48a5e36207156fb792fa79d29925d2f7901e8)的比例越大，此時設定一閾值rth![r_{\text{th}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/fb6b8271224198503ca3f7ae00885109c37d986d)，若R大於(rth+1)2/rth![(r_{\text{th}} + 1)^2/r_{\text{th}}](https://wikimedia.org/api/rest_v1/media/math/render/svg/73b660da2385d488a38f9835b7eac57ec556a3f5)表示此關鍵點位置不合需求因此可以去除。

一般來說，設定閾值rth=10![r_{\text{th}} = 10](https://wikimedia.org/api/rest_v1/media/math/render/svg/50a9a1e4b81a496d7162f7d1cd16cb0bc6ff24c9)

### 方位定向[[編輯](https://zh.wikipedia.org/w/index.php?title=尺度不變特徵轉換&action=edit&section=8)]

在方位定向中，關鍵點以相鄰像素的梯度方向分布作為指定方向參數，使關鍵點描述子能以根據此方向來表示並具備旋轉不變性。

經高斯模糊處理後的影像L(x,y,σ)![L \left( x, y, \sigma \right)](https://wikimedia.org/api/rest_v1/media/math/render/svg/2563247cc6b706b24931d9929a76e1b7772f1f1f)，在σ![\sigma ](https://wikimedia.org/api/rest_v1/media/math/render/svg/59f59b7c3e6fdb1d0365a494b81fb9a696138c36)尺寸下的梯度量m(x,y)![m \left( x, y \right)](https://wikimedia.org/api/rest_v1/media/math/render/svg/5cf451cd06c180bb1b3085864ac77d7eb5b31899)與方向θ(x,y)![\theta \left( x, y \right)](https://wikimedia.org/api/rest_v1/media/math/render/svg/d6f1a3f26d22780c94396a15dbcbd5f9e41731ad)可由相鄰之像素值計算:





計算每個關鍵點與其相鄰像素之梯度的量值與方向後，為其建立一個以10度為單位36條的直方圖。每個相鄰像素依據其量值大小與方向加入關鍵點的直方圖中，最後直方圖中最大值的方向即為此關鍵點的方向。若最大值與局部極大值的差在20%以內，則此判斷此關鍵點含有多個方向，因此將會再額外建立一個位置、尺寸相同方向不同的關鍵點。

針對最後算出的方向還有許多優化步驟，為了符合人體的視覺感官，在加入梯度量值到直方圖時會乘以距離權重(高斯函數)，以減低離關鍵點較遠的影響程度。為了增加角度的解析度，不同角度在加入值方圖時也需考量線性的權重，依照其角度偏移各區間平均值的量，照比例分配於兩個區間內。最後可將值方圖以差補的方式求得某個特定的角度值，而非一固定的區間。

### 關鍵點描述子[[編輯](https://zh.wikipedia.org/w/index.php?title=尺度不變特徵轉換&action=edit&section=9)]

找到關鍵點的位置、尺寸並賦予關鍵點方向後，將可確保其移動、縮放、旋轉的不變性。此外還需要為關鍵點建立一個描述子向量，使其在不同光線與視角下皆能保持其不變性，並且能夠輕易與其他關鍵點作區分。

為了使描述子在不同光線下保有不變性，需將描述子正規化為一128維的單位向量。 首先每個4*4的子區域內建立一個八方向的直方圖，且在關鍵點周圍16*16的區域中——共4*4個子區域，計算每個像素的梯度量值大小與方向後加入此子區域的直方圖中，共可產生一個128維的資料——16個子區域*8個方向。此外為了減少非線性亮度的影響，把大於0.2的向量值設為0.2，最後將正規化後的向量乘上256，且以8位元無號數儲存，可有效減少儲存空間。

## 應用[[編輯](https://zh.wikipedia.org/w/index.php?title=尺度不變特徵轉換&action=edit&section=10)]

### 利用SIFT特徵進行物體辨識[[編輯](https://zh.wikipedia.org/w/index.php?title=尺度不變特徵轉換&action=edit&section=11)]

SIFT能夠找出獨特的關鍵點，此關鍵點不會受移動、轉動、縮放、[仿射變換](https://zh.wikipedia.org/wiki/仿射变换)、亮度等外在因素的影響而改變其特性。因此能夠有效應用在物體辨識上，其步驟包含：

- 輸入偵測物，並執行SIFT演算法找出輸入影像中不變的特徵。

- 這些特徵會與SIFT特徵資料庫作描述子配對，配對將透過[最近鄰居法](https://zh.wikipedia.org/wiki/最近鄰居法)來完成。為了增加可信度，將會移除最近距離與第二近距離大於0.8的配對，這將能夠有效移除背景造成的錯誤配對。此外為了提升最近鄰居法的計算速度，應用best-bin-first演算法能夠有夠高機率找出最近的距離並加快搜尋速度。

- 去除錯誤的配對後，仍有不同物體的成功配對，因此需將成功的配對加以分類，將相同物體的分類分在一起並移除不同物體的分類，因此應用了[霍夫變換](https://zh.wikipedia.org/wiki/霍夫變換)。如此一來便能夠辨認擁有相同角度的特徵點，這些特徵點有很高機率是同一個物件的，因此能夠分出各個特徵群。

- 對於每個被挑選出來的特徵群，使用最小平方法求得輸入影像與訓練資料間最佳的仿射變換參數。運用此參數對各個特徵點作比對，調整參數直到特徵點皆能正確仿射沒有錯誤發生為止。

### 機器人地圖感知與導航[[編輯](https://zh.wikipedia.org/w/index.php?title=尺度不變特徵轉換&action=edit&section=12)]

### 全景圖縫合[[編輯](https://zh.wikipedia.org/w/index.php?title=尺度不變特徵轉換&action=edit&section=13)]

SIFT的特徵匹配可以用於圖像縫合，用於對非全景圖的全自動全景重建。從輸入圖像中提取出來的SIFT特徵能夠通過每一個圖像的特徵匹配K個最近相鄰圖像。隨後，這種對應關係可以用於對每一個圖像尋找m個候選匹配圖像。匹配圖像間的單應性（Homographies）可以通過使用隨機抽樣一致（RANSAC）來得出。由於對於輸入圖像沒有限制，圖像的搜索應用於匹配圖像對的連接部分。因此每一個連接部分都將會對全景圖的構建產生影響。最後，對於所有的連接部分，可以使用光束法平差（Bundle adjustment）來連結照相參數，於是全景圖就可以通過多頻段混合來描繪出來。由於SIFT啟發了全景圖拼接的目標識別方法，拼接結果的系統將會對於順序，方向，尺度和圖像亮度不敏感。在這裡，輸入圖像可以包含多個全景和噪聲圖像，全景序列將會作為結果被識別和描繪。

#### Q2: 列舉分割的幾種方式，四種以上的分割方法

作者：FATRI

多数的图像分割算法均是基于灰度值的不连续和相似的性质。在前者中，算法以灰度突变为基础分割一幅图像，如图像边缘分割。假设图像不同区域的边界彼此完全不同，且与背景不同，从而允许基于灰度的局部不连续性来进行边界检测。后者是根据一组预定义的准则将一幅图像分割为相似区域，如阈值处理、区域生长、区域分裂和区域聚合都是基于这种方法形成的。下面将对每类算法进行详细说明。

<img src="https://pic4.zhimg.com/50/v2-a197becf6c6edbae35f95d9a2a3c0d93_hd.jpg" data-caption="" data-size="normal" data-rawwidth="1000" data-rawheight="667" class="origin_image zh-lightbox-thumb" width="1000" data-original="https://pic4.zhimg.com/v2-a197becf6c6edbae35f95d9a2a3c0d93_r.jpg"/>

图像边缘分割：边缘是图像中灰度突变像素的集合，一般用微分进行检测。基本的边缘检测算法有：Roberts算子、Prewitt算子、Sobel算子。稍高级的算法有：Marr-Hilderth边缘检测器、Canny边缘检测器。

<img src="https://pic2.zhimg.com/50/v2-e4ec63de7d0eeac0b12b61a3117a5369_hd.jpg" data-caption="" data-size="normal" data-rawwidth="1000" data-rawheight="667" class="origin_image zh-lightbox-thumb" width="1000" data-original="https://pic2.zhimg.com/v2-e4ec63de7d0eeac0b12b61a3117a5369_r.jpg"/>

图像阈值分割：由于阈值处理直观、实现简单且计算速度快，因此阈值处理在分割应用中处于核心地位。阈值处理可以分为单阈值处理与多阈值处理。在单阈值处理中最常用且分割效果也不错的算法是Otsu（最大类间方差算法）算法。多阈值处理：K类由K-1个阈值来分离，即计算图像的多个类间方差，多阈值处理的分割结果相较于单阈值的结果虽然会更好一些，但分类数量增加时它会开始失去意义，因为我们仅仅处理一个变量（灰度），此时可以通过增加变量如彩色来进行解决。

<img src="https://pic4.zhimg.com/50/v2-b7e091a6d1abde1f9114db43431a66c5_hd.jpg" data-caption="" data-size="normal" data-rawwidth="1000" data-rawheight="667" class="origin_image zh-lightbox-thumb" width="1000" data-original="https://pic4.zhimg.com/v2-b7e091a6d1abde1f9114db43431a66c5_r.jpg"/>

基于区域的分割：区域生长算法和区域分裂与聚合都是属于基于区域的分割算法。区域生长算法是根据预先定义的生长准则将像素或子区域组合为更大的区域的过程。基本方法是从一组“种子”点开始，将与种子预先定义的性质相似的那些邻域像素添加到每个种子上来形成这些生长区域（如特定范围的灰度或颜色）。区域分裂与聚合是首先将一幅图像细分为一组任意的不相交区域，然后按照一定规则聚合、分裂这些区域。

形态学分水岭算法：分水岭的概念是以三维形象化一幅图像为基础的。在图中，我们主要考虑三种类型的点：（1）属于一个区域最小值的点；（2）把一点看成是一个水滴，如果把这些点放在任意位置上，水滴一定会下落到一个单一的最小值点；（3）处在该点的水会等可能性地流向不止一个这样的最小值点。对于一个特定的区域最小值，满足条件（2）的点的集合称为该最小值的汇水盆地或分水岭。满足条件（3）的点形成地表面的峰线，称之为分割线或分水线。为了达到更好的分割效果，常常将分水岭算法应用到梯度图像上，而不是图像本身。

回想「分水嶺算法」：隨機地在圖像中丟「水珠」；水珠根據「灰度層級」由高到低下流。

總會到一個點，該處具有局部的極小值，水珠就會在這裡匯聚。

當發現兩個不同極小值積累起來的「水潭」產生了可能合併的風險的時候，就在他們的接縫處標記「水壩」以阻止兩灘水匯聚。

直到最後的水珠越來越多，畫面上除了水和水壩，就沒有別的陸地了。

此時，「水壩」就是我們想要的那個分界線。