# 2019/09/24

## SE-302 Compilers

今天我们要讲的是一种文法判断的方法。

### 方法一：Top Down Parsing

从顶向下的 parse，常用的实现是「递归下降法」。

假设我们现在已经有了一组 `Tokens`: 

```
t1 t2 t3 t4 t5
```

如果合法的话，应该能构成一个 `Parse Tree`。

因为我们用的是 Top -> Down，因此我们从根儿上开始构造。

基本上按照自顶向下，从左向右的顺序。

```
E -> T + E|T
T -> int | int * T | (E)
```

留意到我们上面的文法是（加法和乘法）右结合的，且乘法优先级高于加法。

### 开始举例

我们用这个 Token Stream 来举例：

```
int5 * int2
```

我们现在用这两个 Production 一个一个来尝试。

1. E0 -> T1 + E2，
   
   1. T1 -> (E3)，显然原柿子里面没有做括号。完蛋。
   
   2. T1 -> int，这个 Match 了。但是发现 + 跟原来的 `*` token 匹配不上，不 Match。再找！
   
   3. T1 -> `int * T`，这个勉强 Match，但之后 T1 是匹配不上的（哪来的 + 呢）
   
   4. 没得选了，看来最开头一个 Production 就走错了。回溯！

2. 我们现在用另一个产生柿来做。换成 `E0 -> T`！
   
   1. ……
   
   2. 让我们来试试 `T -> int * T`。Match 了！
      
      1. 然后 T -> int。匹配出了 `int * int`！

大概就是这样进行自顶向下的 Token Stream Match 了……

如果找过了所有都还没成功…

这种题么，带回溯的递归还是比较难编写的…（想想你的 LC）

#### 情况说明

Top Down Parsing 啊，并不是总能用的。

我们刚才用的是右结合的文法。为什么？

因为左结合 Sometimes doesn't work. 并不是总对的。

考虑 `S -> S a` 这种文法。这会带来什么问题吗？

`S -> S a -> S S a -> S S S a -> ...`

我好像总是拿不出来一个 Token，总可能还有机会，总把自己拿去尝试…

结果就是无限递归，停不下来。Left-recursive grammar 如果有了一个 Non-Terminal S，这种情况就会造成 Infinite Loop。

#### 解决方案

消左递归的方法：

以 `S -> S a|b` 为例。将其重写为 `S -> bS, S' -> aS' | epsilon`。

按照语义将其改写为不包含左递归的形式。这样的方法可以解决这个问题。

### 优缺点

因为回溯递归的原因，unpopular。大家都不爱使用这种方法。当年 70 年代提出的时候，大家觉得效率太低，又是穷举又是递归回溯的…

但事实上这是最通用的办法了。如果想要简化，那就只能结合具体的文法针对性写算法了。

### 方法二：Predictive Parsers

预测式 Parse，类似上面的 Recursive Descent，但是我先从 Input 里面找 token，去猜测我该使用哪种产生式。

为了做预测，我们往前走一点，往前看 k 个字符来做猜测，进而比较有针对性地去尝试产生式的方法，同时可以筛选掉一些完全不符合条件的产生式。

因为你是去「猜」的，所以必定是需要了解特定的文法，比如他的哪些 Token 对应哪些产生式啊？Token 的格式是啥样啊？你总得知道。

提前 peek `k` 个字符的算法唤做 `LL(k)`。

（最常用的 `LL(1)`。也就是仅仅提前吃一个 Character。但这也跟文法有关…）

这种代码适合手写…因为严重跟原文法有关，且难以自动生成。

另外，事实上 LL 不好处理表达式。对于固定的类似于 if then else print begin end 等词法单位，还是很好处理的。

#### 问题解决

为了解决 LL 不好处理表达式的问题，我们进行一下 Left-Factored Grammer。

比如：当我们發现要搞一个 Expression 出来的时候，我们要去在一张 2 × 2 的表里头找。

这张表行代表当前要找的目标类型（Statement？Expression？Terminal？），列代表要拿到的下一个 Token 的类型（int，+，×，（，），¥ 等）

然后行和列组合拿到了要进行的 Action。于是就知道下一步怎么走了。

|     | int   | *   | +   | （   | ）   |
| --- | ----- | --- | --- | --- | --- |
| T   | int Y |     |     | (E) |     |
| E   | T X   |     |     | T X |     |
| X   |       |     | + E |     | ε   |
| Y   |       | *T  | ε   |     | ε   |

如果有了这张表，程序就能自然自动地进行 Tree Parse 工作了。

算出所有的 Non-T 的 First，这会为我们下面计算 Follow Sets 产生帮助。

然后进一步，我们还可以计算出 Follow(An)，算出来一个 An 后面可能跟的 Token 的集合。例如：

```
Follow( + ) = { int, ( } 
Follow( * ) = { int, ( } 
Follow( ( ) = { int, ( } 
Follow( E ) = {), $} 
Follow( X ) = {$, ) } 
Follow( T ) = {+, ) , $} 
Follow( ) ) = {+, ) , $} 
Follow( Y ) = {+, ) , $} 
Follow( int ) = {*, +, ) , $}
```

计算方法：

```
Add First(A1) – {epsilon} to Follow(X). 
Stop if epsilon !in First(A1)   

Add First(A2) – {epsilon} to Follow(X). 
Stop if epsilon !in First(A2)  

…  

Add First(An) – {epsilon} to Follow(X). 
Stop if epsilon !in First(An)  

// 如果到最后每一个 First(An) 里面都有 epsilon，
// 那么 Follow(Y) 也可以作为 Follow(X) 来用，补进去
Add Follow(Y) to Follow(X)
```

直到最后，我们就可以构造那张 LL(1) Parsing Table 了。

### Error Recovery

出错之后，我们总是希望尽可能多进行一些错误检查，多爆一些错误才好。

有两种思路可以往下进行：

#### a. Insert a Token

缺了啥东西我给你补上，接着编译（

但有个问题：如果说你补的策略不恰当，补了又补，有可能产生一坨死循环。永远地往下补了下去。

#### b. Delete Tokens

这个方案就是：这行写的不对？我给你全删掉（接着往下走

这样的好处就是：这种策略一定是收敛的（因为程序长度是有限的），不会删出死循环的。


