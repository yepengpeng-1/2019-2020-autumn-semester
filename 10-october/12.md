# Oct 12 Sat

今天补上周二的课。Compilers + CSE + RenDie。

噩梦。

## SE-302::Compilers

回忆一下我们之前所学到的东西，重新理一理自从 Syntax 之后的内容。

### 形式文法

什么是文法？

Formal Grammar 指的是一套符号和变换规则的组合。这套变换规则也可以叫做「产生式」，因为她的形式就是**指定了某些符号组合如何被另外一些符号组合替换**。

非终止符（NonTerminal）即为在一个产生式左边的符号，它可以借由这个产生式产生另外的符号列。

反过来不能被「产生式」变换的符号就称为终止符（Terminal）了。

P.S. 变换总得有个开始，因此我们一般指定一个特殊字符 S 作为一个特殊的初始符号来开启所有的变换。如果没有制定 S，那么就认定产生式中第一个非终止符为 S。

### 上下文无关文法

看名字，这是基于形式文法的一种扩展。然而它的特点是基于「产生式」，即变换规则的限制：按照任何一个产生式总可以进行一种「自由」的替换（如 V => w），即永远可以将字符 V 自由变换为字符串 w，而不需要考虑 V 的上下文。

### 悲报

```clike
2019-10-31

Midterm Exam，在上课教室进行考试。
```

### Symbol Table

符号表开了个头。

问题在于：在不同的 Scope 内，符号表是不同的，也就是同一个符号可能代表不同的含义。

我们该如何处理 Scope 事宜呢？

### Binding

我们比较关心的是每一个符号代表的意义（如符号的类型，值等）。

我们会声明一个形如这样的绑定：s1 = {A ⟼ int}，就是把符号跟他的类型 Bind 到一起。

它代表的是符号 A 是个 int 类型的符号。就是这么简单的绑定而已。

随着我们往下扫描整块代码，我们会发现一个个更多的绑定，比如我们会遇到新的变量，形如：

s2 = {B ⟼ int, A ⟼ int}

s3 = {A ⟼ string}

这样一些其他的绑定。

当我们在内层 Scope 声明了一个和外部 Scope 同名的变量，怎么办呢？

我们会得到两个不同的绑定。但是我们要注意：引用的时候始终按照内层优先。

也就是说，后声明的 Binding 优先生效。

另外注意：在一个 Scope 结束的时候，它内部定义的局部变量（即局部 Binding）应该被清理掉才对。

### Binding 的实现

现在有两种不同的实现方法：

* 函数式风格（Functional Style）
  
  * 在覆盖一个变量的时候，不修改原来的旧变量，而是新增一个同名变量
  
  * 通过一些「查找顺序」之类的策略来保证 Scope 策略正确

* 命令式风格（Imperative Style）
  
  * 在覆盖一个变量的时候，真实地改掉这个变量，被覆盖的变量消失
  
  * 但是在 Scope 退出的时候，还要 Undo 来回到覆盖之前的状态
  
  * 也就是说，需要维护一个 Undo Stack（撤销栈）

事实上两种方法都不是很复杂。

### 多重符号表

特别的，我们有一个「多重符号表」的说法。

考虑到一些高级语言有类似于 `namespace` 的设计，也就是可能在不同的代码段会有完全不同的符号表。因此我们可能会有多个活跃环境同时存在。

Java 语言中允许向前饮用（Forward Reference）。在同一个 Scope 内部的子 Scope 之前没有先后关系，他们可以互相引用彼此。

![](https://raw.githubusercontent.com/yuetsin/private-image-repo/master/2019/10/12-08-24-49-2019-10-12-08-24-46-image.png)

比如，这里 E、N、D 都会被放入 `package M` 的名字空间。作为 M 的名字空间的一部分，自然 E、N、D 都可以访问彼此，而无论其在源代码中的位置如何。![](https://raw.githubusercontent.com/yuetsin/private-image-repo/master/2019/10/12-08-25-02-2019-10-12-08-24-59-image.png)

### 高效的命令式风格符号表

为了高效呢…我们会使用一个 Open Hash 表（带有外部散列链的散列表）。

Open Hash 表遇到两个 Hash 值撞了的时候，就用链表链长长一串。

但是 Close Hash 不准用链表，要放在一块定大小的数组里面，在满了的时候得 Rehash（重新 Hash 来应付。）。这个实现起来比 Open 的要难很多。

这里我们还是用一个 Open Hash Table。

加入的新的 Symbol 要插在链表的前端；

这样可以保证我们在沿着链表查找的时候，始终会先找到内层 Scope 的 Symbol。

同时我们在恢复原有状态的时候，直接遍历链并进行 `pop` 就行了。

### 高效的函数式风格符号表

上面的 Imperative 实现本质上还是改变了原来那个表。（往里面插入了一个重复 Key 的 Binding，且在链表的更前端，也就是后面那个永远不可能被访问到，相当于被删除了。）

但我们希望能够保留原有的外层 Namespace，也就是同时保持多个名字空间活跃。如何是好？

这种情况下，直接食用散列表的效率会比较低下。直接 Copy 整个 Hash Table 老费劲了。

我们需要稍微进行一些改进。

或许我们可以不去 Copy 整个 HashTable，而仅仅去拷贝 Array 部分，但修改外部链部分来插入我们的「私货」。类似于这样：

![](https://raw.githubusercontent.com/yuetsin/private-image-repo/master/2019/10/12-08-57-37-2019-10-12-08-57-34-image.png)

右边那一块就是拷贝的 Array，Mouse 就是新加入的 Binding Symbol。

为了让这件事更加高效，我们还是用了 BST（二叉查找树）来存储链，确保每一个节点的访问速度都不会超过 `log(n)`。

### Tiger 里的实现

* Tiger 语言中 Symbol 的 Binding 不直接拿字符串来 Bind，而是直接把指向那个 `const char *` 的指针拿来做 Binding。因为存储多个字符串费空间，而且比较起来还慢。

* 使用破坏-更新式 Hash Table（Imperative Style）来对应 Strings 和 Symbols。

```c++
#define TABSIZE 127
typedef struct binder_ *binder;
struct binder_ {
    void *key; void *value;     /* a binding */
    void *prevtop;                /* to implement a stack */
    binder next;                 /* imperative style */  
};

struct TAB_table_ {
      binder table[TABSIZE];
      void *top;
};

typedef struct TAB_table_ *TAB_table;     
```

`binder_` 的 `key/value` 是很自然的必备字段；

`binder_ *next` 则是用来形成链的指针字段。

而 `void *prevtop` 是给栈这种数据结构用的，也就是实现那个 Undo Stack 用的。

#### 特殊符号

`marksym`: 定义为 `S_symbol("<mark>", 0);` 的本不可能出现的 Symbol Binding。

用来标记 Symbol 用的。

#### BeginScope & EndScope

调用 `S_beginScope` 的时候，等于是嵌套了一层 Scope，因此加入一个特殊的 MarkSym（对，就是上面那个特殊符号）来标记 Scope 的开始。

于是在调用 `S_endScope` 的时候，会持续进行 `pop` 操作，直到我们遇到那个标记用的 `MarkSym`。把它也 `pop` 掉。这样就算除掉了一个 Scope。

#### 两张 Symbol Table

类型的 Binder 和变量的 Binder 是分开的。

for-type identifier 和 for-value identifier...

大概就是这样的吧。

#### Type Bindings

Type 是怎么 Bind 的呢？

我们有一个 `Ty_ty_`...

「类型类型」

```c++
typedef struct Ty_ty_*     Ty_ty;

typedef struct Ty_tyList_* Ty_tyList;
typedef struct Ty_field_* Ty_field typedef struct Ty_fieldList_* Ty_fieldList;
struct Ty_ty_ {
    enum { Ty_record, 
           Ty_nil, 
           Ty_int, 
           Ty_string, 
           Ty_array, 
           Ty_name, 
           Ty_void 
         } kind;
    union {
        Ty_fieldList record;
        Ty_ty        array;
        struct {
            S_symbol sym;
            Ty_ty    ty;
        } name;
    } u;
};

struct Ty_tyList_ {
    Ty_ty     head;
    Ty_tyList tail;
};

struct Ty_field_ {
    S_symbol name;
    Ty_ty    ty;
};

Ty_fieldList {
    Ty_field     head;
    Ty_fieldList tail;
};
```

#### Tiger 的 Type Equivalent

```tiger
 let type a =  { x: int, y:int }
        type b = { x: int, y:int }
        var i : a := …
        var j : b := …
    in i := j
 end /* illegal */

let type a =  { x: int, y:int }
        type c = a
        var i : a := …
        var j : c := …
    in i := j
 end /* legal */
```

在 Tiger 里头，即使是内存布局完全一致的自定义类型也是不一样的 Type。

但是直接赋值相等的 `type c = a` ，`c` 和 `a` 则可以互相赋值。

#### Base Environment

最基本的一个 Environment：啥都还没声明的环境。

这里头放些啥呢？

对于类型来说，int、string 之类的基本数据应该初始化；

`Ty_int` 和 `Ty_string`，好像 Tiger 也就这两个 built-in 类型（

#### Function

作为一个函数，我们在意的包括：

* 她的名字

* 她的参数列表的类型

* 她的返回值

Function 跟 Variable 我们都把它们放在变量里面。

用这个枚举值来区分。

`enum {E_varEntry, E_funEntry} kind;`

如果是 Function，我们要记录下她的返回值和她的参数列表（formals）。

```c++
typedef E_enventry_ *E_enventry; 
struct E_enventry_ {
    enum { E_varEntry, E_funEntry } kind;
    union {
        struct { Ty_ty ty; } var;
        struct {
            Ty_tyList formals; 
            Ty_ty result;
        } fun;    
    } u;
 };

E_enventry E_VarEntry(Ty_ty ty);
E_enventry E_FunEntry(Ty_list formals, Ty_ty result);
```

我们也会在 `base_env` 里提供一些 built-in Functions，如下：

![](https://raw.githubusercontent.com/yuetsin/private-image-repo/master/2019/10/12-09-40-03-2019-10-12-09-40-01-image.png)

## SE-227::CSE

上回啊，咱们说道（说书人腔）…

…RPC. Remote Procedure Call.

> 一种用来给 Server 提出请求的方式。

…NFS. Network File System.

> 一个神奇的网络文件系统。

…CAP Theorem. Eternal Question.

> 一个不可调和的矛盾…

今天的内容。

…GFS. Google File System. (is it?)

…CDN. Content Distribution Network.

…DNS. Domain Name System.

### RPCs

RPC 并非仅仅用于 NFS 的实现。事实上它的作用要大得多。

例如，Microservices 就是一个例子。

如果我们使用 RPC 作为通信协议，那么就不用特地在意我这个请求是被哪台机器处理的；服务提供者也不用担心每个请求会被哪台机器处理；只需要我们给那些负载较大的请求种类多分配一些资源，就好了。

### RPC::流程

1. 客户端调用客户端stub（client stub）。这个调用是在本地，并将调用参数push到[栈](https://zh.wikipedia.org/wiki/栈)（stack）中。
2. 客户端stub（client stub）将这些参数包装，并通过系统调用发送到服务端机器。打包的过程叫 [marshalling](https://zh.wikipedia.org/wiki/Marshalling_(计算机科学))。（常见方式：[XML](https://zh.wikipedia.org/wiki/XML)、[JSON](https://zh.wikipedia.org/wiki/JSON)、二进制编码）
3. 客户端本地操作系统发送信息至服务器。（可通过自定义[TCP协议](https://zh.wikipedia.org/wiki/传输控制协议)或[HTTP](https://zh.wikipedia.org/wiki/HTTP)传输）
4. 服务器系统将信息传送至服务端stub（server stub）。
5. 服务端stub（server stub）解析信息。该过程叫 [unmarshalling](https://zh.wikipedia.org/wiki/Unmarshalling_(计算机科学))。
6. 服务端stub（server stub）调用程序，并通过类似的方式返回给客户端。

### RPC:: Failure Handling

在遇到错误的时候，我们该怎么做？

#### At least once

如果请求失败了，就不断 Retry，Retry，Retry，直到成功为止。

这个问题很大，没个停

#### At most once

这个问题也比较大；At most once 意味着我们得记住每个历史请求，

才能判断这是否是 Twice or more。

#### Exactly once

理想是 Exactly once.

### Differences

Client 跟 Server 都需要安全验证。彼此都认为对方是不可信的。

RPC 又名 Web Service。介于 HTTP 和 Socket 之间的抽象。

### GFS

GFS::Google File System

谷歌文件系统

``` wiki
GFS专门为Google的核心数据即页面搜索的存储进行了优化。数据使用大到若干G字节的大文件持续存储，而这些文件极少被删除、覆盖或者减小；通常只是进行添加或读取操作。它也是针对Google的计算机集群进行的设计和优化，这些节点是由廉价的“常用”计算机组成，这就意味着必须防止单个节点的高损害率和随之带来的数据丢失。其它设计理念包括高数据吞吐率，甚至这带来了访问反应期变差。
节点分为两类：主节点和Chunkservers。Chunkservers存储数据文件，这些单个的文件象常见的文件系统中的簇或者扇区那样被分成固定大小的数据块（这也是名字的由来）。每个数据块有一个唯一的64位标签，维护从文件到组成的数据块的逻辑映射。每个数据块在网络上复制一个固定数量的次数，缺省次数是3次，对于常用文件如可执行文件的次数要更多。
主服务器通常并不存储实际的大块数据，而是存储与大块数据相关的元数据，这样的数据如映射表格将64位标签映射到大块数据位置及其组成的文件、大块数据副本位置、哪个进程正在读写特定的大数据块或者追踪复制大块数据的“快照”（通常在主服务器的激发下，当由于节点失败的时候，一个大数据块的副本数目降到了设定的数目下）。所有这些元数据通过主服务器周期性地接收从每个数据块服务器来的更新（“心跳消息”）保持最新状态。
操作的允许授权是通过限时的、倒计时“租期”系统来处理的，主服务器授权一个进程在有限的时间段内访问数据块，在这段时间内主服务器不会授权其它任何进程访问数据块。被更改的chunkserver——总是主要的数据块存储器，然后将更改复制到其它的chunkserver上。这些变化直到所有的chunkserver确认才存储起来，这样就保证了操作的完整性和原子性。
访问大数据块的程序首先查询主服务器得到所要数据块的位置，如果大数据块没有进行操作（没有重要的租约），主服务器回答大数据块的位置，然后程序就可以直接与chunkserver进行联系接收数据（类似于Kazaa和它的超级节点）。
```

Wiki 上是这么说的…

#### 具体的操作

1. Client 发送请求，带上参数 `(file name, chunk index)`
2. GFS Master 就会通过元数据来找出对应的 Chunk，并给 Chunkserver 发送指令
3. Chunkserver 会频繁跟 Master 通信，通过心跳包报告自己还活着

注意：

* 这里虽然有一个 filename，但事实上并没有目录这回事。因为保存目录在 Chunk 里实在太浪费，一层层读取 Chunk 又太慢。所以干脆直接把 file 的完全路径（如 `/usr/foo/bar`）给拿来 Hash。这个唤作 Flatten Path。
* Chunkserver 有很多个。主服务器聆听这些 Chunkserver 的心跳。
* Master 会成为瓶颈吗？Google 实践说明：并不会。（辩解：）Master 其实没什么活要干，也不会经常崩；所以 GFS 就只设计了一个 GFS Master。 

#### 适用范围

GFS 专门为 Google 的核心数据即页面搜索的存储进行了优化。数据使用大到若干 GiB 的大文件持续存储，而这些文件极少被删除、覆盖或者减小。

